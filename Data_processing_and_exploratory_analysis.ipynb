{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "# SQL \n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import _mysql\n",
    "\n",
    "# Natural language processing for sentiment analysis\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "# Plot\n",
    "import pylab as plt\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import Range1d\n",
    "output_notebook()\n",
    "%matplotlib inline\n",
    "\n",
    "# Sentiment scores converted to a pickle dump file\n",
    "import pickle\n",
    "\n",
    "mysqlFilePath = 'mysql://root:@localhost/clientsuccess?charset=utf8&use_unicode=0'\n",
    "\n",
    "'''\n",
    "Thie function replaces two special characters that correspond to True and False \n",
    "in the MySQL dump file that I received from the startup company that I consulted for.\n",
    "'''\n",
    "def replace_special(char):\n",
    "    try:\n",
    "        if char.encode('string-escape') == r'\\x01':\n",
    "            return True\n",
    "        elif char.encode('string-escape') == r'\\x00':\n",
    "            return False\n",
    "        else:\n",
    "            return char\n",
    "    except:\n",
    "        return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(mysqlFilePath, pool_recycle=3600)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table_names has all the names of tables that I received as a MySQL dump file.\n",
    "table_names = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        table_name \n",
    "    FROM \n",
    "        information_schema.tables \n",
    "    WHERE \n",
    "        table_schema='clientsuccess';\n",
    "    \"\"\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SaaS company ID = tenant_id\n",
    "# Companies' customer ID = client_id\n",
    "# start_date = subscription start date\n",
    "# end_date = subscription end date\n",
    "tb_client_subscription =  pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        tenant_id, client_id, product_id, start_date, end_date, termination_date, amount\n",
    "    FROM \n",
    "        client_subscription;  \n",
    "        \"\"\",connection).applymap(lambda x: replace_special(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Communication records between the SaaS companies and their customers are retrieved. \n",
    "# note = email content\n",
    "tb_client_note = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        id AS client_note_id, note, subject, created_date_time, client_id, interaction_type_id\n",
    "    FROM\n",
    "        client_note\n",
    "    ;\n",
    "    \"\"\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The most recent date in pdSeriesDates that is before Jan 1 2017 will be returned. \n",
    "If nothing found, pd.NaT is returned.\n",
    "'''\n",
    "def getmax(pdSeriesDates):\n",
    "    dates = pdSeriesDates.apply(pd.to_datetime).sort_values(ascending = False)\n",
    "    for date in dates:\n",
    "        if pd.Timestamp(date) < pd.Timestamp('2017-01-01'):\n",
    "            return date\n",
    "    return pd.NaT\n",
    "\n",
    "# The most recent date in pdSeriesDates is returned.\n",
    "def findmax(pdSeriesDates):\n",
    "    return pdSeriesDates.apply(pd.to_datetime).max()\n",
    "\n",
    "'''\n",
    "tb_client is a pandas dataframe that has all the client information including\n",
    "tenant_id = each client's tenant_id\n",
    "start_date = very beginning among all the subscriptions\n",
    "end_date_for_subscription = end date of the most recent subscription\n",
    "end_date = end date of the most recent subscription that ended before Jan 1 2017.\n",
    "'''\n",
    "tb_client = pd.DataFrame()\n",
    "tb_client['tenant_id'] = tb_client_subscription\\\n",
    "    .groupby('client_id')['tenant_id'].max()\n",
    "tb_client['start_date'] = tb_client_subscription\\\n",
    "    .groupby('client_id')['start_date'].min()    \n",
    "tb_client['end_date_for_subscription'] =  tb_client_subscription\\\n",
    "    .groupby('client_id')['end_date'].apply(findmax)\n",
    "tb_client['end_date'] = tb_client_subscription\\\n",
    "    .groupby('client_id')['end_date']\\\n",
    "    .apply(getmax)\n",
    "tb_client['client_id'] = tb_client.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_client_new = tb_client[tb_client['end_date'].apply(type) != pd._libs.tslib.NaTType].copy(deep=True)\n",
    "tb_client_new['churned'] = tb_client_new[['end_date', 'end_date_for_subscription']].\\\n",
    "    apply(lambda x: False if ((x['end_date'] < x['end_date_for_subscription'])\\\n",
    "                              or (type(x['end_date_for_subscription']) == pd._libs.tslib.NaTType)) else True, axis=1)\n",
    "tb_client = tb_client_new\n",
    "tb_client_new = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the clients that all the end date is NaT.\n",
    "mask = tb_client['end_date'].apply(type) == pd._libs.tslib.NaTType\n",
    "tb_client = tb_client.drop(tb_client[mask].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numbers of communications per month for individual clients are computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "freq_per_client recieves the id number of a client and returns \n",
    "the client's number of communications with its tenant company\n",
    "per month as a pandas Frame. \n",
    "'''\n",
    "def freq_per_client(client_id, freq):\n",
    "    g = tb_client_note[tb_client_note['client_id'] == client_id]\\\n",
    "        .groupby(pd.Grouper(key='created_date_time', freq = freq))\n",
    "    return pd.DataFrame(g.size())\n",
    "\n",
    "'''\n",
    "Numbers of communications per month for individual clients are \n",
    "stored in the column 'client_note_M_freq' of the tb_client dataframe. \n",
    "'''\n",
    "tb_client['client_note_M_freq'] = tb_client['client_id'].apply(lambda x: freq_per_client(x, 'M'))\n",
    "\n",
    "'''\n",
    "fnt_freq_days_to_renewal recieves the id number of a client and retruns\n",
    "the client's number of communications with its tenant company per month \n",
    "in [time_list, freqency_list] format, where time_list is the number of \n",
    "days before the last subscription renewal date, and thus it ranges between \n",
    "-365 days to 0 day.\n",
    "'''\n",
    "def fnt_freq_days_to_renewal(client_id, freq):\n",
    "    newindex = tb_client.loc[client_id]['client_note_'+freq+'_freq'].index-tb_client.loc[client_id]['end_date']\n",
    "    temp =  pd.DataFrame(tb_client.loc[client_id]['client_note_'+freq+'_freq'].iloc[:,0].tolist(), index = newindex)\n",
    "    temp1 = temp.loc[pd.Timedelta(days=-365):pd.Timedelta(days=0)]\n",
    "    if len(temp1) != 0:\n",
    "        xx = temp1.index\n",
    "        xx = xx.days\n",
    "        yy = temp1.iloc[:,0].tolist()\n",
    "        return [xx, yy]\n",
    "    return [None, None]\n",
    "\n",
    "'''\n",
    "Numbers of communications per month for individual clients with respect to \n",
    "the days before the last subscription renewal are stored in the column \n",
    "freq_days_to_renewal.\n",
    "'''\n",
    "tb_client['freq_days_to_renewal'] = tb_client['client_id'].apply(lambda x: fnt_freq_days_to_renewal(x, 'M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numbers of communications for every 3 months for individual clients are computed.Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_client['client_note_3M_freq'] = tb_client['client_id'].apply(lambda x: freq_per_client(x, '3M'))\n",
    "tb_client['3M_freq_days_to_renewal'] = tb_client['client_id'].apply(lambda x: fnt_freq_days_to_renewal(x, '3M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment scores are computed for every 3 month email notes from individual clients. The NLTK Vader sentiment pyton packageis used. This step takes a while!!! So, the next code block was commented out, but its output was saved in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# sentiment_scores receives client_id as an input and returns [time_list, sentiment_list], \n",
    "# where time_list is the number of days before the last subscription renewal date, and thus\n",
    "# it ranges between -365 days to 0 day. sentiment_list is the corresponding sentiment scores for \n",
    "# every 3 months. \n",
    "# '''\n",
    "# def sentiment_scores(client_id):\n",
    "#     sid = SentimentIntensityAnalyzer()\n",
    "#     neutral_dict = 0\n",
    "\n",
    "#     g = tb_client_note[tb_client_note['client_id'] == client_id]\\\n",
    "#         .groupby(pd.Grouper(key='created_date_time', freq='3M'))\\\n",
    "#         .apply(lambda x: x['note'].str.cat(sep=' '))\n",
    "#     # remove special characters like markup language angle brackets to speed up the sentiment analysis.\n",
    "#     g = g.apply(lambda x: re.sub('<[^>]*>', ' ', x))\n",
    "#     g = g.apply(lambda x: re.sub('[ \\t\\r\\n\\v\\f]', ' ', x))\n",
    "#     dict_scores = g.apply(lambda x: sid.polarity_scores(x) if type(x) == str else neutral_dict).tolist()\n",
    "    \n",
    "#     # The 'compound' score was used for the sentiment. \n",
    "#     scores =[]\n",
    "#     for i in range(len(dict_scores)):\n",
    "#         scores.append(dict_scores[i]['compound'])\n",
    "    \n",
    "#     newindex = tb_client.loc[client_id]['client_note_3M_freq'].index-tb_client.loc[client_id]['end_date']\n",
    "#     newindex = [x.days for x in newindex]\n",
    "\n",
    "#     mask = [True if x >=-365 and x<=0 else False for x in newindex]\n",
    "#     newindex = [y for y,x in zip(newindex, mask) if x == True]\n",
    "#     scores = [y for y,x in zip(scores, mask) if x == True]\n",
    "#     if len(newindex) == 0:\n",
    "#         newindex = [None]\n",
    "#     if len(scores) == 0:\n",
    "#         scores = [None]\n",
    "#     return [newindex, scores]\n",
    "\n",
    "# tb_client['sentiment_3M'] = [[[None], [None]]]*len(tb_client)\n",
    "# sent_list = [[[None], [None]]]*len(tb_client)\n",
    "\n",
    "# for i in range(len(tb_client)):   \n",
    "#     sent_list[i] = sentiment_scores(tb_client.iloc[i]['client_id'])\n",
    "#     print i, \" \",\n",
    "\n",
    "# df_sentiment = pd.DataFrame(sent_list, index = tb_client['client_id'])\n",
    "# pickle.dump(df_sentiment, open(\"sentiment.p\", \"wb\"))\n",
    "# df_sentiment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pickle file \"sentiment.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sent = pickle.load( open( \"sentiment.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of communications during 1 year (if data exist) before a renewal date is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fnt_sum(df):\n",
    "    return int(df.sum())\n",
    "\n",
    "tb_client['client_note_total_count'] = tb_client['freq_days_to_renewal']\\\n",
    "    .apply(lambda x: int(sum(x[1])) if x[1] != None else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of email communications for every month is plotted over time. First, only churn cases were considered. As shown in the graph, there was no systematic trend of the communication frequency over time (i.e., no pattern in frequency momentum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_hist(str_column, isChurned, ymin = 0, ymax = 160):\n",
    "    mask = tb_client['churned'].tolist()\n",
    "    if isChurned:\n",
    "        ma = [x for x, m in zip(range(len(tb_client)), mask) if m == True]\n",
    "    else:\n",
    "        ma = [x for x, m in zip(range(len(tb_client)), mask) if m == False]\n",
    "\n",
    "    p=figure(plot_width=800, plot_height=300, y_range = Range1d(ymin, ymax))\n",
    "\n",
    "    for i in ma[0:100]:\n",
    "        [x,y] = tb_client.iloc[i][str_column]\n",
    "        p.line(x, y, line_width=5, line_alpha = 0.2)\n",
    "    p.xaxis.axis_label = 'Days to renewal date'\n",
    "    p.yaxis.axis_label = 'Number of communications per 3 months'\n",
    "    show(p)\n",
    "    \n",
    "plot_hist('freq_days_to_renewal', isChurned = True, ymax = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For non-churn cases. Again, there is no systematic frequency momentum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist('freq_days_to_renewal', isChurned=False, ymax = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To reduce noise, number of communications for every \"3\" months is used. Again, I did not see any systematic frequency momentum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist('3M_freq_days_to_renewal', isChurned=True,ymax=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist('3M_freq_days_to_renewal', isChurned=False, ymax = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# end_date = end date of the last subscription\n",
    "tb_client['end_date'] = tb_client['end_date'].apply(pd.Timestamp)\n",
    "\n",
    "# start_date = start date of the 1st subscription\n",
    "tb_client['start_date'] = tb_client['start_date'].apply(pd.Timestamp)\n",
    "temp = tb_client['end_date'] - tb_client['start_date']\n",
    "\n",
    "# sub_duration = entire period of subscriptions\n",
    "tb_client['sub_duration'] = temp.apply(lambda x: x.days)\n",
    "\n",
    "# last_subscription_start_date = start date of teh last subscription\n",
    "endDate = tb_client['end_date']\n",
    "lst = [tb_client_subscription[tb_client_subscription['client_id']==x] for x in tb_client.index]\n",
    "startdate_list = [lst[i][lst[i]['end_date'].apply(pd.Timestamp) == endDate.iloc[i]]['start_date'].iloc[0]\n",
    "     for i in range(len(lst))]\n",
    "tb_client['last_subscription_start_date'] = pd.Series(startdate_list, index = tb_client.index)\n",
    "temp = tb_client['end_date'].apply(pd.Timestamp) \\\n",
    "    - tb_client['last_subscription_start_date'].apply(pd.Timestamp)\n",
    "\n",
    "# last_sub_duration = duration of the last subscription. \n",
    "tb_client['last_sub_duration'] = temp.apply(lambda x: x.days)\n",
    "\n",
    "# amount = paid price for subscription\n",
    "amount_list = [lst[i][lst[i]['end_date'].apply(pd.Timestamp) == endDate.iloc[i]]['amount'].iloc[0]\n",
    "     for i in range(len(lst))]\n",
    "tb_client['amount'] = pd.Series(amount_list, index = tb_client.index)\n",
    "\n",
    "# amount_per_day = paid price for subscription per day on average\n",
    "tb_client['amount_per_day'] = tb_client['amount'].div(tb_client['last_sub_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_churn = tb_client['churned'].tolist()\n",
    "mask_non_churn = [not x for x in mask_churn]\n",
    "\n",
    "p=figure(plot_width=800, plot_height=300)\n",
    "\n",
    "p.circle(tb_client['client_note_total_count'][mask_non_churn], \\\n",
    "         tb_client['sub_duration'][mask_non_churn], size=10, alpha = 0.4, color='green')\n",
    "p.circle(tb_client['client_note_total_count'][mask_churn], \\\n",
    "         tb_client['sub_duration'][mask_churn], size=10, alpha = 0.4, color='red')\n",
    "p.xaxis.axis_label = 'Number of email communications for 1 year'\n",
    "p.yaxis.axis_label = 'Entire duration of subscriptions'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_churn = tb_client['churned'].tolist()\n",
    "mask_non_churn = [not x for x in mask_churn]\n",
    "\n",
    "p=figure(plot_width=800, plot_height=300, x_range = Range1d(-1, 10000))\n",
    "\n",
    "p.circle(tb_client['amount_per_day'][mask_non_churn], \\\n",
    "         tb_client['sub_duration'][mask_non_churn], size=10, alpha = 0.4, color='green')\n",
    "p.circle(tb_client['amount_per_day'][mask_churn], \\\n",
    "         tb_client['sub_duration'][mask_churn], size=10, alpha = 0.4, color='red')\n",
    "p.xaxis.axis_label = 'Amount paid per day on average'\n",
    "p.yaxis.axis_label = 'Entire duration of subscriptions'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The sentiment score over one year period was stored in the column 'sentiment' in the table tb_client. The tb_client dataframe was stored in mysql table, 'kim_all_tenants'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sent = pickle.load( open( \"sentiment.p\", \"rb\" ) )\n",
    "lst =[sum(x) if x!=[None] else None for x in df_sent.loc[:, 1]]\n",
    "df_sent['sentiment'] = pd.Series(lst, index = df_sent.index)\n",
    "tb_client['sentiment'] = df_sent['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_result = tb_client[tb_client['amount_per_day'] != np.inf]\n",
    "column_names = ['tenant_id', 'start_date', 'end_date_for_subscription', 'end_date',\\\n",
    "               'churned', 'client_note_total_count', 'sub_duration', 'last_subscription_start_date',\\\n",
    "               'last_sub_duration', 'amount_per_day', 'sentiment']\n",
    "tb_result[column_names].to_sql(con=engine, name='kim_all_tenants', if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
