{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import _mysql\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import itertools as itertools\n",
    "\n",
    "# Plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "from bokeh.sampledata.autompg import autompg as df\n",
    "%matplotlib inline\n",
    "output_notebook()\n",
    "\n",
    "# kslearn packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# smoothing \n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# regular expression\n",
    "import re\n",
    "\n",
    "mysqlFilePath = 'mysql://root:@localhost/clientsuccess?charset=utf8&use_unicode=0'\n",
    "\n",
    "def replace_special(char):\n",
    "    try:\n",
    "        if char.encode('string-escape') == r'\\x01':\n",
    "            return True\n",
    "        elif char.encode('string-escape') == r'\\x00':\n",
    "            return False\n",
    "        else:\n",
    "            return char\n",
    "    except:\n",
    "        return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function prints and plots the confusion matrix.\n",
    "Normalization can be applied by setting `normalize=True`.\n",
    "\"\"\"\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "   \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine(mysqlFilePath, pool_recycle=3600)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_name = \"kim_large_churn_tenants1\"\n",
    "tb_res =  pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \n",
    "        %s\n",
    "        \"\"\"%db_name, connection).applymap(lambda x: replace_special(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RF(features, Xtrain, ytrain, test_size = 0.3, n_estimators = 10, max_depth = 3, class_weight = None):\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth = max_depth, class_weight = class_weight)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    coeff = clf.get_params()\n",
    "\n",
    "    print coeff\n",
    "\n",
    "    print(\"score: %.4f\" % clf.score(X_test, y_test))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vector construction (non-normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    \n",
    "    # tenant company features\n",
    "    lst_tenants = df['tenant_id'].unique()\n",
    "    \n",
    "    for x in lst_tenants:\n",
    "        name = \"tenant\"+str(x)\n",
    "        mask = (df['tenant_id'] == x)\n",
    "        mask = [1 if x == True else 0 for x in mask]\n",
    "        df[name] = pd.Series(mask, index = df.index)\n",
    "\n",
    "    tenant_names = [\"tenant\"+str(x) for x in lst_tenants]\n",
    "    \n",
    "    # including the other features.\n",
    "    feature_lst = ['client_note_total_count', 'sub_duration', 'last_sub_duration', 'amount_per_day', 'sentiment']\\\n",
    "        + tenant_names\n",
    "    \n",
    "    X_original = df[feature_lst].as_matrix()\n",
    "    y = np.array(df['churned'])\n",
    "    return X_original, y , feature_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_table_plot(y_test, y_pred):\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "\n",
    "    class_names = ['Non-Churn','Churn']\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original, y, feature_lst = data_preprocessing(tb_res)\n",
    "scaler = StandardScaler()\n",
    "X_raw = scaler.fit_transform(X_original)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y, test_size=.3, random_state = 70)\n",
    "\n",
    "clf = RF(feature_lst, X_train, y_train, n_estimators = 1000, max_depth = 10, class_weight=\"auto\")\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_table_plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall was improved significantly. Now it is 86%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance scores were computed for companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(feature_importance_lst, feature_lst):\n",
    "    p=figure(plot_width=800, plot_height=200)  \n",
    "    df = pd.DataFrame()\n",
    "    df['importance'] = pd.Series(feature_importance_lst , index = feature_lst)\n",
    "    p = Bar(df, values='importance',title=\"Feature Importance\", legend=False,\\\n",
    "            plot_width=800, plot_height=300)\n",
    "    p.xaxis.axis_label = 'Features'\n",
    "    p.yaxis.axis_label = 'Importance'\n",
    "    show(p)\n",
    "                    \n",
    "plot_importance(clf.feature_importances_, feature_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall curve was improved significantly when compared with the case that all the tenant companies were considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(clf, X_test, y_test):\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "    plt.plot(recall, precision, lw = 1, color='navy',label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\"Precision-Recall: Random Forest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(clf, X_test, y_test):\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr_rt, tpr_rt, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr_rt, tpr_rt)\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr_rt, tpr_rt, color='darkorange',lw=lw, label='Random Forest (area = %0.2f)' % roc_auc)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "plot_ROC(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all tenant companies, predicted and true churn numbers are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst_cl =[]\n",
    "lst_true = []\n",
    "lst_pred = []\n",
    "lst_corr = []\n",
    "lst_tenants = tb_res['tenant_id'].unique()\n",
    "\n",
    "tb_res['churned_pred'] = pd.Series(clf.predict(X_raw), index = tb_res.index)\n",
    "#tb_res['churned_pred'] = pd.Series(clf_reduced.predict(X), index = tb_res.index)\n",
    "for tid in lst_tenants:\n",
    "    df_t = tb_res[tb_res['tenant_id'] == tid]\n",
    "    num_cl = len(df_t)\n",
    "    num_true_churn = df_t['churned'].sum()\n",
    "    num_pred_churn = df_t['churned_pred'].sum()\n",
    "    num_corr_churn = (df_t['churned'] & df_t['churned_pred']).sum()\n",
    "    #print num_cl, \"\\t\", num_true_churn, \"\\t\", num_pred_churn, \"\\t\", num_corr_churn\n",
    "    lst_cl.append(num_cl)\n",
    "    lst_true.append(num_true_churn)\n",
    "    lst_pred.append(num_pred_churn)\n",
    "    lst_corr.append(num_corr_churn)\n",
    "    \n",
    "df_churn = pd.DataFrame(index = lst_tenants)\n",
    "df_churn['total_clients'] = lst_cl\n",
    "df_churn['true_churn'] = lst_true\n",
    "df_churn['pred_churn'] = lst_pred\n",
    "df_churn['correctly_pred_churn'] = lst_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_churn['churn_rate'] = df_churn['true_churn']/df_churn['total_clients']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the tenant ID 173 and 132, recall was now significantly better. When considering all tenants together, the random forest classifier could not detect any churn cases for the two tenant companies. Now, the RF classifier can do much better.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With this every encouraging results, I computed all the probability for renewal for individual customers and for different number of email communications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_cus_prob make a plot for renewl probability for a given customer feature vector (normalized).\n",
    "# x_axis of the plot is normalized frequency. It needs to be converted back to the \"unnormalized\" frequency.\n",
    "\n",
    "def plot_cus_prob(clf, x_norm, x_original):\n",
    "    #lst = np.array(range(-15,16))/15.\n",
    "    #lst = [np.power(3, x) for x in lst]\n",
    "    lst = np.array(range(300))/300.*(X_train[:,0].max()-X_train[:,0].min()) + X_train[:,0].min()\n",
    "    #print lst\n",
    "    Xinit = x_norm\n",
    "    f0 = []\n",
    "    for alpha in lst:\n",
    "        perturb = np.array(([1,0] + [0]*(len(Xinit)-2)))*alpha\n",
    "        x = np.array([0, Xinit[1]] + list(Xinit[2:]))\n",
    "        f0.append(x + perturb)\n",
    "    f0= np.array(f0)\n",
    "\n",
    "    y_score = clf.predict_proba(f0)[:, 0]\n",
    "\n",
    "    p=figure(plot_width=400, plot_height=200, x_range = Range1d(X_train[:,1].min(),X_train[:,1].max() ),\\\n",
    "            y_range = Range1d(start=0, end=100))\n",
    "    \n",
    "    \n",
    "    \n",
    "    p.line(f0[:,0], y_score*100, line_width = 4, alpha=0.4)\n",
    "    p.xaxis.axis_label = 'Number of communications per year'\n",
    "    p.yaxis.axis_label = 'Satisfaction level'\n",
    "    p.circle(Xinit[0], clf.predict_proba([Xinit])[:, 0]*100, size = 10, color = \"purple\", alpha = 0.7)\n",
    "    \n",
    "    # filter window length = 13 \n",
    "    # degree 2 polynomial function used for fitting.\n",
    "    y_score_smoothed = savgol_filter(y_score, 21, 2)\n",
    "    p.circle(f0[:,0], y_score_smoothed*100)\n",
    "    show(p)\n",
    "    \n",
    "    freq = x_original[0]\n",
    "    freq1 = x_original[1]\n",
    "    p = y_score_smoothed[0]\n",
    "    p1 = y_score_smoothed[1]\n",
    "    delp = p - p1\n",
    "    delfreq = freq-freq1\n",
    "    # print delfreq/freq\n",
    "    \n",
    "    elasticity = (freq * delp)/(delfreq * p)\n",
    "    return elasticity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of tenants\n",
    "# I chose tenant id = 147\n",
    "index_lst = tb_res[tb_res['tenant_id']==147].index\n",
    "# 2 clients are considered.\n",
    "index_lst = index_lst[48:50]\n",
    "x_originals = [X_original[item] for item in index_lst]\n",
    "x_norms = scaler.transform(x_originals)\n",
    "\n",
    "lst = []\n",
    "for x_norm, x_original in zip(x_norms, x_originals):\n",
    "    lst.append(plot_cus_prob(clf, x_norm, x_original))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
